{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df06e0e-cfa0-4ac0-87b9-a6d29cf25121",
   "metadata": {},
   "source": [
    "### **$$Response \\ to \\ Marketing \\ Campaign \\ by \\ SparkCognition$$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e9d60c-fd61-4828-be06-e82a0033af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c3cdde-a27e-40e7-8f31-d38c4097e9a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Response_to_marketing_campaign/datasets/marketing_training.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Response_to_marketing_campaign/datasets/marketing_training.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Response_to_marketing_campaign/datasets/marketing_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Response_to_marketing_campaign/datasets/marketing_training.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Response_to_marketing_campaign/datasets/marketing_training.csv')\n",
    "test_df = pd.read_csv('/Response_to_marketing_campaign/datasets/marketing_test.csv').drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc69e42-2c41-4091-b935-978492232060",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head(5))\n",
    "train_df.name = 'Training_Data'\n",
    "display(test_df.head(5))\n",
    "test_df.name = 'Testing_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966339c-7828-4ec1-b7b5-a25c4239be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808a89f-fd0c-4a4a-92ec-f97b106fac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153eddc-5088-493c-979a-ab6c59f519f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df.isnull().sum()/7414)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953b94c-d3a0-4e88-898d-671a641b3138",
   "metadata": {},
   "source": [
    "### **~ Observation:**\n",
    "\n",
    "- The columns `'custAge'`,`'schooling'` and `'day_of_week'` columns consist of null values. with `'custAge'` has approx 24% null values, `'schooling'` has approx 29% null values and lastly `'day_of_week'` has approx 9.5% null values.\n",
    "\n",
    "### **@ Approach:**\n",
    "\n",
    "- As the mentioned columns have quite a number of null values hence dropping the rows won't be feasible.\n",
    "- Instead of dropping the rows we can fill the numeric column that is `'custAge'` with **mean** or **median** and categorical columns `'schooling'` and `'day_of_week'` with **mode**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878facc3-3ff8-4f9f-88e7-beb967ab26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Customer Age we impute with mean or median as its numerical column\n",
    "print('******************************* Treating the null values in customer age column ***************************************')\n",
    "custAge_mean = int(train_df[train_df['custAge'].isna()==False].custAge.mean())\n",
    "custAge_median = int(train_df[train_df['custAge'].isna()==False].custAge.median())\n",
    "\n",
    "print('********************************************* Mean Imputation *********************************************************')\n",
    "\n",
    "mean_impute = train_df.custAge.fillna(custAge_mean)\n",
    "plt.hist(mean_impute,bins = 20,color = 'blue',edgecolor = 'black')\n",
    "plt.title('Distribution of Customer Age After Mean Imputation')\n",
    "plt.xlabel('Customer Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha = 0.75)\n",
    "plt.show()\n",
    "\n",
    "print('********************************************* Median Imputation *******************************************************')\n",
    "\n",
    "median_impute = train_df.custAge.fillna(custAge_median)\n",
    "plt.hist(median_impute,bins = 20,color = 'blue',edgecolor = 'black')\n",
    "plt.title('Distribution of Customer Age After Median Imputation')\n",
    "plt.xlabel('Customer Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha = 0.75)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d167f-92ff-4186-a760-5727cb565659",
   "metadata": {},
   "source": [
    "### **~ Observation:**\n",
    "\n",
    "- The histogram of `custAge` shows a similar **left-skewed** distribution when missing values are filled with either the **mean** or the **median**.\n",
    "### **@ Approach:**\n",
    "- Since both give similar results and **median** is generally more robust to skewed data, we will proceed with **median imputation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fd3d7-4910-4954-af26-c2ad1cf19894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.custAge = train_df.custAge.fillna(custAge_median) \n",
    "test_df.custAge = test_df.custAge.fillna(custAge_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757f835-5111-4c29-a4fe-281fae73fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputaiton of Schooling and day_of_week columns\n",
    "\n",
    "print('******************************* Treating the null values in schooling and day_of_week column ***************************************')\n",
    "\n",
    "schooling_mode = train_df[train_df['schooling'].isna()==False]['schooling'].mode()[0]\n",
    "day_of_week_mode = train_df[train_df['day_of_week'].isna()==False]['day_of_week'].mode()[0]\n",
    "print(f\"Mode of schooling column is : {schooling_mode}\")\n",
    "print(f\"Mode of day_of_week column is : {day_of_week_mode}\")\n",
    "train_df.schooling = train_df.schooling.fillna(schooling_mode) # imputation with mode as categorical column\n",
    "train_df.day_of_week = train_df.day_of_week.fillna(day_of_week_mode) # imputation with mode as categorical column\n",
    "test_df.schooling = test_df.schooling.fillna(schooling_mode) # imputation with mode as categorical column\n",
    "test_df.day_of_week = test_df.day_of_week.fillna(day_of_week_mode) # imputation with mode as categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e442f7-c9a3-49bc-a772-6cef9c537bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2eaae7-e5f3-430e-86ef-3650702043c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [train_df,test_df]\n",
    "for i in lst:\n",
    "    print(f\"************************************************** {i.name} ****************************************************************\")\n",
    "    for j in i.columns:\n",
    "        print(j)\n",
    "        print(i[j].unique())\n",
    "        print(len(i[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb780a-4ff8-4198-b72f-e8e3a4870bbd",
   "metadata": {},
   "source": [
    "<div align=\"left\">\n",
    "\n",
    "### **~ Observation:**\n",
    "\n",
    "- After printing the unique values in each column, it was observed that some columns contain `'unknown'` as a value.  \n",
    "- While this is not technically null, it still represents missing or uninformative data.  \n",
    "- We can either **impute** these values using appropriate strategies (such as **mode imputation**),  \n",
    "  or treat `'unknown'` as a **separate category** and **encode** it accordingly.\n",
    "\n",
    "### **@ Approach:**\n",
    "\n",
    "- I plan to check the count of `'unknown'` values in each column first.\n",
    "- If the `'count'` is relatively **small**, Iâ€™ll consider imputing them (e.g., with the mode for categorical features).\n",
    "- But if the count is high, I might treat `'unknown'` as a separate **category** and **encode** it instead.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5865e6-73ea-41b8-b87c-50fac95b0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_df.columns:\n",
    "    if train_df[i].dtype=='object':\n",
    "        print(f\"****************************************************** {i} **********************************************************\")\n",
    "        print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc90f01-b09a-4316-acd6-f66a228dce7e",
   "metadata": {},
   "source": [
    "### **~ Observation & Imputation Strategy:**\n",
    "\n",
    "It can be observed that most of the **`unknown`** entries form a **small percentage** of the total values.  \n",
    "- For example out of 7414 entries the following columns:  \n",
    "  - `profession` has 61 unknowns.   \n",
    "  - `marital` has 8 unknowns.  \n",
    "  - `schooling` has 231 unknowns.    \n",
    "  - `housing` & `loan` has 168 unknowns each.\n",
    "- Except for `default` column with 1432 unknowns out of the 7414 entries which is significantly higher compared to the rest.\n",
    "\n",
    "### **@ Approach**:\n",
    "- For columns where **`unknown`** appeared less number of time, those were imputed using statistical measures like **mode**.\n",
    "- For **`default`**, where the number of `unknown` entries are **high**, this **`unknown's`** are treated as a separate category and are encoded to preserve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef475c82-a0d5-4d5b-9b21-7fbd9b7aec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_unknowns = ['profession','marital','schooling','housing','loan']\n",
    "for i in columns_with_unknowns:\n",
    "    train_df[i] = train_df[i].replace('unknown',train_df[i].mode()[0])\n",
    "    test_df[i] = test_df[i].replace('unknown',train_df[i].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7f72d-8fc9-457b-932d-7b179141c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['responded'] = train_df['responded'].map({'yes':1,'no':0}).astype(int)\n",
    "train_numeric = []\n",
    "train_categorical = []\n",
    "for i in train_df.drop('responded',axis = 1).columns:\n",
    "    if train_df[i].dtype=='object':\n",
    "        train_categorical.append(i)\n",
    "    else:\n",
    "        train_numeric.append(i)\n",
    "print(train_categorical)\n",
    "print(train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a8b99-91eb-4d35-aebc-3b5a6c81770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numeric = []\n",
    "test_categorical = []\n",
    "for i in test_df.columns:\n",
    "    if test_df[i].dtype=='object':\n",
    "        test_categorical.append(i)\n",
    "    else:\n",
    "        test_numeric.append(i)\n",
    "print(test_categorical)\n",
    "print(test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf390e8-fbf5-4716-8477-9d4a7820bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_df = pd.get_dummies(train_df[train_categorical], drop_first = True).astype(int).join(train_df[train_numeric])\n",
    "train_encoded_df['responded'] = train_df['responded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41458e57-12d5-4bb1-8487-75cf2e8c2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_df = pd.get_dummies(test_df[test_categorical], drop_first=True).astype(int).join(test_df[test_numeric])\n",
    "test_encoded_df = test_encoded_df.reindex(columns=train_encoded_df.columns.drop('responded'), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d65d4b-7d88-462c-843f-ba8682099bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_flags = ['schooling_illiterate','default_yes','month_mar','month_sep','poutcome_nonexistent',\n",
    "                          'poutcome_success','pdays','previous','pmonths','pastEmail']\n",
    "for i in possible_flags:\n",
    "    print(train_encoded_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e4ab1-0435-4eaf-82d0-b6ea77f6fbb9",
   "metadata": {},
   "source": [
    "### **~ Observation:**\n",
    "\n",
    "- There are columns with only 1 or 2 positive samples like **`schooling_illiterate`** and **`default_yes`**.\n",
    "\n",
    "- The columns **`pdays`** and **`pmonths`** basically tells when was the person contacted. \n",
    "\n",
    "- The columns **`months`**, **`poutcome_success`**, **`previous`** and **`pastEmail`** are informative can be kept as it is.\n",
    "\n",
    "### **@ Approach**:\n",
    "\n",
    "- Dropping columns **`schooling_illiterate`** and **`default_yes`** as doesn't adds much value to the overall analysis.\n",
    "\n",
    "- Transforming the columns **`pdays`** and **`pmonths`** into binary\n",
    "\n",
    "- Also, outlier detection was considered, but due to the imbalanced nature of the dataset and risk of losing minority class information, no aggressive outlier removal or capping was applied. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8364f-08d5-4cbe-9f3d-6f23b0bb97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_df.drop(['schooling_illiterate','default_yes'],axis = 1,inplace = True)\n",
    "test_encoded_df.drop(['schooling_illiterate','default_yes'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1980c-6a8d-4735-82fd-666e39326b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_df['pdays'] = train_encoded_df['pdays'].apply(lambda x: 0 if x==999 else 1).astype(int)\n",
    "train_encoded_df['pmonths'] = train_encoded_df['pmonths'].apply(lambda x: 0 if x==999 else 1).astype(int)\n",
    "test_encoded_df['pdays'] = test_encoded_df['pdays'].apply(lambda x: 0 if x==999 else 1).astype(int)\n",
    "test_encoded_df['pmonths'] = test_encoded_df['pmonths'].apply(lambda x: 0 if x==999 else 1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230625f1-c1e3-40fe-8170-bc20a140b36d",
   "metadata": {},
   "source": [
    "### **~Observation :**\n",
    "- The output class is highly imbalance.\n",
    "### **@Approach :**\n",
    "\n",
    "- Apply SMOTE only on training data only to avoid leakage.\n",
    "- Also, it balances the dataset by synthesizing new minority samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8c261-a232-4a68-affd-58ba36d0dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(train_encoded_df.drop('responded',axis=1),train_encoded_df['responded'],test_size = 0.2,random_state = 42,shuffle = True)\n",
    "X_resampled, y_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0b38f-4fc8-4a4e-9583-e368f3b6c129",
   "metadata": {},
   "source": [
    "### **AdaBoost Classifier :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e8917-d59d-409f-8811-eb02ef714762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.6, 0.05)\n",
    "f1_scores = {t: [] for t in thresholds}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_resampled, y_resampled), 1):\n",
    "    X_train, X_val = X_resampled.iloc[train_idx], X_resampled.iloc[val_idx]\n",
    "    y_train, y_val = y_resampled.iloc[train_idx], y_resampled.iloc[val_idx]\n",
    "    ab.fit(X_train, y_train)\n",
    "    y_proba = ab.predict_proba(X_val)[:, 1]\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        f1_scores[thresh].append(f1_score(y_val, y_pred))\n",
    "        accuracy = accuracy_score(y_val,y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "avg_f1 = {t: np.mean(scores) for t, scores in f1_scores.items()}\n",
    "best_thresh = max(avg_f1, key=avg_f1.get)\n",
    "print(f\"Best Threshold is {best_thresh} and Average F1 score is {avg_f1[best_thresh]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbe588-5dc2-486a-9f2e-99d771e82bc7",
   "metadata": {},
   "source": [
    "### **Decision Tree Classifier :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8761a-f520-4480-8f91-85914c0ee692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.6, 0.05)\n",
    "f1_scores = {t: [] for t in thresholds}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_resampled, y_resampled), 1):\n",
    "    X_train, X_val = X_resampled.iloc[train_idx], X_resampled.iloc[val_idx]\n",
    "    y_train, y_val = y_resampled.iloc[train_idx], y_resampled.iloc[val_idx]\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        f1_scores[thresh].append(f1_score(y_val, y_pred))\n",
    "        accuracy = accuracy_score(y_val,y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "avg_f1 = {t: np.mean(scores) for t, scores in f1_scores.items()}\n",
    "best_thresh = max(avg_f1, key=avg_f1.get)\n",
    "print(f\"Best Threshold is {best_thresh} and Average F1 score is {avg_f1[best_thresh]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0bfbff-056f-443d-915f-2a8ad022d496",
   "metadata": {},
   "source": [
    "### **Random Forest Classifier :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2db9e-f647-48d3-bf23-e9350efafa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,criterion='gini', max_depth=None)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "thresholds = np.arange(0.1, 0.6, 0.05)\n",
    "f1_scores = {t: [] for t in thresholds}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_resampled, y_resampled), 1):\n",
    "    X_train, X_val = X_resampled.iloc[train_idx], X_resampled.iloc[val_idx]\n",
    "    y_train, y_val = y_resampled.iloc[train_idx], y_resampled.iloc[val_idx]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_proba = rf.predict_proba(X_val)[:, 1]\n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        f1_scores[thresh].append(f1_score(y_val, y_pred))\n",
    "        accuracy = accuracy_score(y_val,y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "avg_f1 = {t: np.mean(scores) for t, scores in f1_scores.items()}\n",
    "best_thresh = max(avg_f1, key=avg_f1.get)\n",
    "print(f\"Best Threshold is {best_thresh} and Average F1 score is {avg_f1[best_thresh]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c5bc5-b02e-4873-96a0-3b96a0994dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = pd.Series(rf.feature_importances_, index=X_resampled.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "imp_features.head(15).plot(kind='bar')\n",
    "plt.title('Top 15 Feature Importances by Random Forest')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xlabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a1d25-a289-4b08-86bf-5b775a47d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = RandomForestClassifier(n_estimators=200, max_depth=None,random_state=42)\n",
    "opt_model.fit(X_resampled, y_resampled)\n",
    "test_proba = opt_model.predict_proba(test_encoded_df)[:,1]\n",
    "test_pred = (test_proba >= best_thresh).astype(int)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75b425-c6e7-46c7-b75d-93eefaebb6dd",
   "metadata": {},
   "source": [
    "<div align=\"left\">\n",
    "\n",
    "### **~ Summary:**\n",
    "\n",
    "- Outlier removal was eliminated to avoid the loss of minority data.\n",
    "- The unknown and near constant features were omitted or coded accordingly.\n",
    "- the colums with one class were dropped like schooling_illiterate or default_yes\n",
    "- Columns like pdays and pmonths were converted to binary for extract the underlying meaning from the data.\n",
    "- Only the training data was used to apply the SMOTE without compromising data leakage.\n",
    "- A RF model used with the threshold to take care of the problem of class imbalance.\n",
    "- Thresholds were chosen with the use of cross-validation to be robust to generalization.\n",
    "- Lastly, feature importance graph was visualized to make it easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef746310-e21a-4530-b139-d62e9c45c8eb",
   "metadata": {},
   "source": [
    "### **Questions & Answers**\n",
    "\n",
    "**1. Describe your model and why did you choose this model over other types of models?**\n",
    "\n",
    "The final model selected is SMOTE+Random Forest Classifier. As SMOTE balances the classes by adding synthetic minority samples, and Random Forest effectively learns from this more balanced data using its ensemble approach.\n",
    "\n",
    "\n",
    "**2. Describe any other models you have tried and why do you think this model performs better?**\n",
    "\n",
    "- **Models tried**:\n",
    "\n",
    "    - **Logistic Regression**: When combined with SMOTE LR achieved high accuracy, but it failed to address the minority class.\n",
    "                               The best threshold achieved was 0.40 with average F1_score = 0.83.\n",
    "    - **AdaBoost**: With SMOTE it Performed slightly better than LR but is sensitive to noise introduced by SMOTE,\n",
    "                    Best threshold achieved was 0.50 with average F1_score = 0.843\n",
    "    - **Decision Tree**: With SMOTE Decision Tree performed better than both LR and AdaBoost, Best threshold achieved was 0.50 with average                           F1_score = 0.8915. But it is prone to overfitting \n",
    "    - **Random forest**: Combined with SMOTE and threshold tuning it Performed better than all the previous models as it combines many                                decision trees, reduces chance of overfitting and captures the complex patterns in the data that was balanced\n",
    "                         after SMOTE, Best average F1 score observed is 0.936 at threshold 0.55.\n",
    "\n",
    "**3. How did you handle missing data?**\n",
    "\n",
    "- Instead of dropping the rows with null values, filled the numeric column that is **`'custAge'`** with **median** as it's more robust to skewed data and categorical columns **`'schooling'`** and **`'day_of_week'`** with **mode**.\n",
    "- For columns where **`unknown`** appeared less number of time, those were imputed using statistical measures like **mode**.\n",
    "- Columns where the number of **`unknown`** entries were **high**, those were treated as a separate category and were encoded to preserve information.\n",
    "- Dropped columns **`schooling_illiterate`** and **`default_yes`** as doesn't adds much value to the overall analysis.\n",
    "- Transforming the columns **`pdays`** and **`pmonths`** into binary to preserve underlying information.\n",
    "\n",
    "**4. How did you handle categorical (string) data?**\n",
    "\n",
    "- Used **one-hot encoding** (`pd.get_dummies`) on categorical features.\n",
    "\n",
    "**5. How did you handle unbalanced data?**\n",
    "\n",
    "- Used **SMOTE** to oversample minority class in training set only to avoid data leakage.\n",
    "\n",
    "**6. How did you test your model?**\n",
    "\n",
    "- Split data into **train/test sets**.\n",
    "- Applied **cross-validation** on training set for robust model selection and threshold tuning.\n",
    "- Final evaluation performed using metrics **precision, recall, F1_score** (not just accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feef862-b01a-4239-8ba0-d6b462c2f32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
